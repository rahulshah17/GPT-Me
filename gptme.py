# -*- coding: utf-8 -*-
"""GPTMe

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f82y0bj0i4WFhB4ZdTirFgc66KAGz24j
"""

!pip install -U bitsandbytes transformers datasets peft accelerate



from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import torch

model_id = "meta-llama/Llama-3.2-3B-Instruct"

# Load tokenizer and 4-bit quantized model
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map="auto",
    torch_dtype=torch.float16,
    load_in_4bit=True
)

from peft import get_peft_model, LoraConfig, TaskType

# Configure LoRA
#model.unload()
lora_config = LoraConfig(
    r=12,
    lora_alpha=16,
    lora_dropout=0.05,
    bias="none",
    target_modules=["q_proj", "v_proj"],  # LLaMA-specific modules
    task_type=TaskType.CAUSAL_LM
)

# Add LoRA adapters to the model
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

training_data = [
    {
        "instruction": "What is Rahul's full name",
        "input": "His fullname is Rahul Hemal Shah, First Name: Rahul, Middle Name: Hemal, Surname: Shah",
        "output": "Rahul Hemal Shah"
    },
    {
        "instruction": "What is Rahul Hemal Shah's current research position?",
        "input": "Rahul Hemal Shah is currently working as a Graduate Student Researcher at Spotify, where he fine-tunes LLaMA models and builds Text-to-SQL frameworks.",
        "output": "Rahul is a Graduate Student Researcher at Spotify in New York City, starting January 2025."
    },
    {
        "instruction": "Describe Rahul's contributions at Spotify.",
        "input": "At Spotify, Rahul Hemal Shah developed an advanced Text-to-SQL framework and implemented preference learning using DPO while fine-tuning LLaMA models on the BIRD benchmark.",
        "output": "He developed a multi-agent Text-to-SQL framework, fine-tuned LLaMA models on the BIRD benchmark, and implemented preference learning using DPO."
    },
    {
        "instruction": "What did Rahul work on during his internship at MSI?",
        "input": "During his internship at MSI, Rahul Hemal Shah developed the Safety Portal application using Angular 17, RxJS, and HTTP interceptors.",
        "output": "He developed the MSI Safety Portal in Angular 17 and improved performance through RxJS Observables, OnPush detection, and HTTP interceptors."
    },
    {
        "instruction": "How did Rahul improve MSI’s web application performance?",
        "input": "Rahul Hemal Shah improved asynchronous API performance using RxJS and optimized CRUD operations, achieving an 80% reduction in processing time.",
        "output": "He improved asynchronous API performance using RxJS and achieved 80% faster automated CRUD testing."
    },
    {
        "instruction": "What frontend framework did Rahul use at MSI?",
        "input": "Rahul Hemal Shah used Angular 17 with TypeScript and Webpack to build MSI's Safety Portal web application.",
        "output": "He used Angular 17 with TypeScript and Webpack."
    },
    {
        "instruction": "What was Rahul’s role at SLB from 2022 to 2023?",
        "input": "From November 2022 to August 2023, Rahul Hemal Shah worked as a Frontend Developer at SLB in Pune, India, where he built responsive applications using ReactJS and optimized code modularity with custom hooks.",
        "output": "He was a Frontend Developer responsible for building responsive apps using ReactJS and improving code modularity with custom hooks."
    },
    {
        "instruction": "How did Rahul manage state in SLB projects?",
        "input": "While working at SLB, Rahul Hemal Shah managed application state using Redux and React Context API and used hooks like useState and useEffect.",
        "output": "He used Redux and React Context API along with hooks like useState and useEffect."
    },
    {
        "instruction": "What backend technologies did Rahul use at SLB as a Full Stack Developer?",
        "input": "During his tenure at SLB as a Full Stack Developer, Rahul Hemal Shah utilized C# (.NET), SQL stored procedures, GraphQL, and deployed services using Docker on AWS.",
        "output": "He used C# (.NET), SQL stored procedures, GraphQL, and Docker on AWS."
    },
    {
        "instruction": "What automation impact did Rahul achieve at SLB?",
        "input": "Rahul Hemal Shah automated multiple workflows at SLB, which led to a revenue increase of over $800,000 and reallocated 42% of development resources.",
        "output": "He automated workflows that generated over $800,000 in revenue and reallocated 42% of resources."
    },
    {
        "instruction": "Describe Rahul's internship at Swym.",
        "input": "During his internship at Swym, Rahul Hemal Shah built an RNN-based recommendation system in Python that increased wishlist engagement by 40%, while also developing backend automation using SQL.",
        "output": "He built an RNN-based recommendation system that increased wishlist engagement by 40% and worked on backend automation in Python and SQL."
    },
    {
        "instruction": "Where is Rahul pursuing his master's degree?",
        "input": "Rahul Hemal Shah is currently pursuing his Master’s in Computer Science at the University of Massachusetts Amherst.",
        "output": "At the University of Massachusetts Amherst, expected to graduate in May 2025."
    },
    {
        "instruction": "What is Rahul's CGPA in his Master’s program?",
        "input": "Rahul Hemal Shah has maintained a CGPA of 3.93 during his Master's in Computer Science at UMass Amherst.",
        "output": "His CGPA is 3.93."
    },
    {
        "instruction": "What courses has Rahul taken during his MS in Computer Science?",
        "input": "Rahul Hemal Shah has completed courses in Advanced Algorithms, Machine Learning, NLP, Systems for Data Science, Neural Networks, and Database Design at UMass Amherst.",
        "output": "He has studied Advanced Algorithms, Machine Learning, NLP, Systems for Data Science, Neural Networks, and Database Design."
    },
    {
        "instruction": "Where did Rahul complete his bachelor's degree?",
        "input": "Rahul Hemal Shah completed his B.Tech. in Electronics and Computer Engineering at Vellore Institute of Technology, Tamil Nadu.",
        "output": "He earned a B.Tech. in Electronics and Computer Engineering from VIT, Tamil Nadu."
    },
    {
        "instruction": "What technical languages does Rahul know?",
        "input": "Rahul Hemal Shah is proficient in Python, C++, JavaScript, TypeScript, Java, C#, SQL, T-SQL, Go, HTML/CSS, R, and jQuery.",
        "output": "Python, C++, JavaScript, TypeScript, Java, C#, SQL, T-SQL, Go, HTML/CSS, R, and jQuery."
    },
    {
        "instruction": "List frameworks Rahul has worked with.",
        "input": "Rahul Hemal Shah has hands-on experience with React, Angular, .NET, Node.js, GraphQL, Bootstrap, PyTorch, TensorFlow, Kafka, and Flutter.",
        "output": "He has experience with React, Angular, .NET, Node.js, GraphQL, Bootstrap, PyTorch, TensorFlow, Kafka, and Flutter."
    },
    {
        "instruction": "What developer tools is Rahul proficient in?",
        "input": "Rahul Hemal Shah is skilled in using Git, Docker, Kubernetes, Azure, AWS, Jira, Jenkins, Dynatrace, Cassandra, and Linux CLI.",
        "output": "Git, Docker, Kubernetes, Azure, AWS, Jira, Jenkins, Dynatrace, Cassandra, and Linux CLI."
    },
    {
        "instruction": "What methodologies is Rahul familiar with?",
        "input": "Rahul Hemal Shah is familiar with REST API design, MySQL, PostgreSQL, MongoDB, NoSQL, Agile methodology, SDLC, and CI/CD workflows.",
        "output": "REST API, MySQL, PostgreSQL, MongoDB, NoSQL, Agile, SDLC, and CI/CD."
    },
    {
        "instruction": "What is SnapScore?",
        "input": "SnapScore is an NLP-based project developed by Rahul Hemal Shah that benchmarks text-to-image models by evaluating semantic fidelity using a custom metric.",
        "output": "SnapScore is an NLP project that evaluates the semantic fidelity of text-to-image models using a novel LLM benchmarking metric."
    },
    {
        "instruction": "What techniques did Rahul use in SnapScore?",
        "input": "Rahul Hemal Shah used ResNet-LSTM for image captioning and fine-tuned Stable Diffusion models for generating high-quality text-to-image results.",
        "output": "He trained ResNet-LSTM for image captioning and fine-tuned Stable Diffusion for text-to-image generation."
    },
    {
        "instruction": "What is StockStream about?",
        "input": "StockStream is a real-time stock analysis project by Rahul Hemal Shah that leverages Apache Kafka for ingestion and PySpark for distributed data processing.",
        "output": "StockStream is a real-time stock analysis system built using Apache Kafka and PySpark for distributed data processing."
    },
    {
        "instruction": "Which API does StockStream use?",
        "input": "StockStream uses the Alpha Vantage API to fetch and stream real-time and historical stock data.",
        "output": "It uses the Alpha Vantage API to stream historical stock data."
    },
    {
        "instruction": "What are Rahul’s published papers about?",
        "input": "Rahul Hemal Shah has published two research papers in Springer, focusing on anomaly detection in drones using machine learning and deep learning methods.",
        "output": "Rahul's focus is on anomaly detection in drones using machine learning techniques."
    },
    {
        "instruction": "How many citations does Rahul’s primary paper have?",
        "input": "Rahul Hemal Shah's main research paper on anomaly detection in drones currently has 6 citations in Springer-indexed journals.",
        "output": "His paper on anomaly detection in drones has 6 citations on Springer."
    },
    {
        "instruction": "Where can I find Rahul online?",
        "input": "Rahul Hemal Shah is available on GitHub at github.com/rahulshah17, LinkedIn at linkedin.com/in/rahulshah1799, and his portfolio site at rahulhemalshah.infinityfreeapp.com.",
        "output": "On GitHub at github.com/rahulshah17, LinkedIn at linkedin.com/in/rahulshah1799, and his portfolio site at rahulhemalshah.infinityfreeapp.com."
    }
]

new_data = [
    {
      "instruction": "What is Rahul Hemal Shah's current research position?",
      "input": "Rahul Hemal Shah is currently working at Spotify as a Graduate Student Researcher starting January 2025.",
      "output": "Rahul Hemal Shah is a Graduate Student Researcher at Spotify in New York City, starting January 2025."
    },
  {
    "instruction": "Describe Rahul Hemal Shah's responsibilities at Spotify.",
    "input": "At Spotify, Rahul Hemal Shah is working on prompt engineering, fine-tuning LLaMA models, and implementing preference learning techniques.",
    "output": "Rahul Hemal Shah developed a multi-agent Text-to-SQL framework, fine-tuned LLaMA models on the BIRD benchmark, and implemented preference learning using DPO."
  },
  {
    "instruction": "Where did Rahul Hemal Shah intern before joining Spotify?",
    "input": "Before Spotify, Rahul Hemal Shah interned at MSI from June 2024 to December 2024.",
    "output": "Rahul Hemal Shah interned at MSI in Orange County, California from June 2024 to December 2024."
  },
  {
    "instruction": "What did Rahul Hemal Shah develop at MSI?",
    "input": "At MSI, Rahul Hemal Shah built the Safety Portal application using Angular 17 and enhanced API performance.",
    "output": "Rahul Hemal Shah developed the MSI Safety Portal application using Angular 17, improving performance with RxJS and OnPush change detection."
  },
  {
    "instruction": "How did Rahul Hemal Shah improve frontend performance at MSI?",
    "input": "Rahul Hemal Shah used OnPush change detection and HTTP interceptors to speed up automated CRUD testing by 80%.",
    "output": "Rahul Hemal Shah improved asynchronous API performance and achieved 80% faster automated CRUD testing using OnPush change detection and interceptors."
  },
  {
    "instruction": "Which frontend frameworks has Rahul Hemal Shah worked with?",
    "input": "Rahul Hemal Shah has experience with Angular 17, ReactJS, and TypeScript.",
    "output": "Rahul Hemal Shah has worked with Angular, ReactJS, TypeScript, and Bootstrap."
  },
  {
    "instruction": "Where did Rahul Hemal Shah work between November 2022 and August 2023?",
    "input": "Rahul Hemal Shah was a Frontend Developer at SLB in Pune, India during this period.",
    "output": "Rahul Hemal Shah worked as a Frontend Developer at SLB (Schlumberger) in Pune, India from November 2022 to August 2023."
  },
  {
    "instruction": "What technologies did Rahul Hemal Shah use at SLB for frontend development?",
    "input": "While at SLB, Rahul Hemal Shah used ReactJS, Redux, Context API, and React Hooks like useState and useEffect.",
    "output": "Rahul Hemal Shah utilized ReactJS, Redux, Context API, and hooks like useState and useEffect during his time at SLB."
  },
  {
    "instruction": "How did Rahul Hemal Shah improve code quality at SLB?",
    "input": "Rahul Hemal Shah increased unit test coverage to 65%, reduced bugs, and followed CI/CD best practices.",
    "output": "Rahul Hemal Shah improved code coverage to 65%, reduced bugs, and ensured high-quality code using CI/CD and Agile practices."
  },
  {
    "instruction": "What backend experience does Rahul Hemal Shah have?",
    "input": "Rahul Hemal Shah has backend experience using C#, .NET, SQL stored procedures, and GraphQL.",
    "output": "Rahul Hemal Shah has worked on backend systems using C#, .NET 6, SQL stored procedures, and GraphQL APIs."
  },
{
        "instruction": "What is Rahul Hemal Shah's current research position?",
        "input": "Rahul Hemal Shah is currently working at Spotify as a Graduate Student Researcher starting January 2025.",
        "output": "Rahul Hemal Shah is a Graduate Student Researcher at Spotify in New York City, starting January 2025."
    },
    {
        "instruction": "Describe Rahul Hemal Shah's responsibilities at Spotify.",
        "input": "At Spotify, Rahul Hemal Shah is working on prompt engineering, fine-tuning LLaMA models, and implementing preference learning techniques.",
        "output": "Rahul Hemal Shah developed a multi-agent Text-to-SQL framework, fine-tuned LLaMA models on the BIRD benchmark, and implemented preference learning using DPO."
    },
    {
        "instruction": "Where did Rahul Hemal Shah intern before joining Spotify?",
        "input": "Before Spotify, Rahul Hemal Shah interned at MSI from June 2024 to December 2024.",
        "output": "Rahul Hemal Shah interned at MSI in Orange County, California from June 2024 to December 2024."
    },
    {
        "instruction": "What did Rahul Hemal Shah develop at MSI?",
        "input": "At MSI, Rahul Hemal Shah built the Safety Portal application using Angular 17 and enhanced API performance.",
        "output": "Rahul Hemal Shah developed the MSI Safety Portal application using Angular 17, improving performance with RxJS and OnPush change detection."
    },
    {
        "instruction": "How did Rahul Hemal Shah improve frontend performance at MSI?",
        "input": "Rahul Hemal Shah used OnPush change detection and HTTP interceptors to speed up automated CRUD testing by 80%.",
        "output": "Rahul Hemal Shah improved asynchronous API performance and achieved 80% faster automated CRUD testing using OnPush change detection and interceptors."
    },
    {
        "instruction": "Which frontend frameworks has Rahul Hemal Shah worked with?",
        "input": "Rahul Hemal Shah has experience with Angular 17, ReactJS, and TypeScript.",
        "output": "Rahul Hemal Shah has worked with Angular, ReactJS, TypeScript, and Bootstrap."
    },
    {
        "instruction": "Where did Rahul Hemal Shah work between November 2022 and August 2023?",
        "input": "Rahul Hemal Shah was a Frontend Developer at SLB in Pune, India during this period.",
        "output": "Rahul Hemal Shah worked as a Frontend Developer at SLB (Schlumberger) in Pune, India from November 2022 to August 2023."
    },
    {
        "instruction": "What technologies did Rahul Hemal Shah use at SLB for frontend development?",
        "input": "While at SLB, Rahul Hemal Shah used ReactJS, Redux, Context API, and React Hooks like useState and useEffect.",
        "output": "Rahul Hemal Shah utilized ReactJS, Redux, Context API, and hooks like useState and useEffect during his time at SLB."
    },
    {
        "instruction": "How did Rahul Hemal Shah improve code quality at SLB?",
        "input": "Rahul Hemal Shah increased unit test coverage to 65%, reduced bugs, and followed CI/CD best practices.",
        "output": "Rahul Hemal Shah improved code coverage to 65%, reduced bugs, and ensured high-quality code using CI/CD and Agile practices."
    },
    {
        "instruction": "What backend experience does Rahul Hemal Shah have?",
        "input": "Rahul Hemal Shah has backend experience using C#, .NET, SQL stored procedures, and GraphQL.",
        "output": "Rahul Hemal Shah has worked on backend systems using C#, .NET 6, SQL stored procedures, and GraphQL APIs."
    },
     {
    "instruction": "Where did Rahul Hemal Shah complete his bachelor's degree?",
    "input": "Rahul Hemal Shah completed his undergraduate education at Vellore Institute of Technology.",
    "output": "Rahul Hemal Shah completed his B.Tech in Electronics and Computer Engineering from Vellore Institute of Technology, Tamil Nadu, India."
  },
  {
    "instruction": "What was Rahul Hemal Shah's CGPA in his undergraduate program?",
    "input": "Rahul Hemal Shah graduated with a CGPA of 8.62 in his B.Tech.",
    "output": "Rahul Hemal Shah earned a CGPA of 8.62 in his undergraduate studies at Vellore Institute of Technology."
  },
  {
    "instruction": "Which programming languages is Rahul Hemal Shah proficient in?",
    "input": "Rahul Hemal Shah is skilled in multiple programming languages including Python, C++, and JavaScript.",
    "output": "Rahul Hemal Shah is proficient in Python, C++, JavaScript, TypeScript, Java, C#, SQL, T-SQL, Go, HTML/CSS, R, and jQuery."
  },
  {
    "instruction": "What are some of the technical tools Rahul Hemal Shah has experience with?",
    "input": "He has worked with various developer tools in both academic and industrial settings.",
    "output": "Rahul Hemal Shah is experienced with Git, Docker, Kubernetes, Microsoft Azure, AWS, Jira, Jenkins, Dynatrace, Cassandra, and Linux CLI."
  },
  {
    "instruction": "What is SnapScore and what did Rahul Hemal Shah do in that project?",
    "input": "SnapScore is a text-to-image evaluation project Rahul Hemal Shah worked on.",
    "output": "Rahul Hemal Shah developed SnapScore, a novel NLP-based technique for evaluating the semantic fidelity of images generated from textual prompts using ResNet-LSTM and Stable Diffusion."
  },
  {
    "instruction": "What was the outcome of Rahul Hemal Shah\u2019s SnapScore project?",
    "input": "He used benchmarks like BLEU and ROUGE to evaluate his models.",
    "output": "The SnapScore project was successfully evaluated using metrics like BLEU, ROUGE, METEOR, and Cosine similarity to assess the quality of image captions."
  },
  {
    "instruction": "What is StockStream and what technologies did Rahul Hemal Shah use in it?",
    "input": "StockStream was built for real-time stock data analysis.",
    "output": "Rahul Hemal Shah built StockStream using Apache Kafka for ingestion and PySpark for distributed data processing of real-time stock data."
  },
  {
    "instruction": "How did Rahul Hemal Shah ensure scalability in StockStream?",
    "input": "StockStream was designed to handle large volumes of historical stock data efficiently.",
    "output": "Rahul Hemal Shah used Alpha Vantage API and distributed processing to ensure scalability, low latency, and fault tolerance in StockStream."
  },
  {
    "instruction": "What topics has Rahul Hemal Shah published research on?",
    "input": "Rahul Hemal Shah has research papers indexed on Springer.",
    "output": "Rahul Hemal Shah has published research on anomaly detection in drones using machine learning and deep learning architectures."
  },
  {
    "instruction": "How many citations does Rahul Hemal Shah's main research paper have?",
    "input": "The paper is available on Springer and Google Scholar.",
    "output": "Rahul Hemal Shah's main research paper on anomaly detection in drones has 6 citations."
  },
  {
    "instruction": "Which tools did Rahul Hemal Shah use for his internship at Swym?",
    "input": "Swym was a remote internship Rahul did during 2021.",
    "output": "During his internship at Swym, Rahul Hemal Shah used Python, SQL, Linux, and SOAP APIs to build backend automation and an RNN-based recommendation system."
  },
  {
    "instruction": "What did Rahul Hemal Shah build during his internship at Swym?",
    "input": "He worked on a recommendation system using deep learning.",
    "output": "Rahul Hemal Shah built a deep learning-based recommendation system using RNNs that improved wishlist engagement by 40%."
  },
  {
    "instruction": "What certifications or citations are associated with Rahul Hemal Shah\u2019s publications?",
    "input": "His papers are available on Springer and have citations.",
    "output": "Rahul Hemal Shah's research papers on anomaly detection in drones have been cited in academic literature, including 6 and 1 citation respectively on Springer."
  },
  {
    "instruction": "What kind of methodologies is Rahul Hemal Shah familiar with?",
    "input": "His resume includes several software development methodologies.",
    "output": "Rahul Hemal Shah is familiar with Agile methodology, REST API, CI/CD pipelines, and the full Software Development Life Cycle (SDLC)."
  },
  {
    "instruction": "What kind of cloud platforms and infrastructure has Rahul Hemal Shah worked with?",
    "input": "His work spans both Microsoft and Amazon cloud platforms.",
    "output": "Rahul Hemal Shah has worked with Microsoft Azure and Amazon AWS for deploying scalable cloud-native applications using Docker and Kubernetes."
  }
]

from datasets import Dataset

dataset = Dataset.from_list(training_data+new_data)

tokenizer.pad_token = tokenizer.eos_token

# Format prompt as instruction-tuned style
def format_prompt(example):
    #return f"<s>[INST] {example['instruction']} [/INST] {example['output']}</s>"
    return f"<s>[INST] {example['instruction']} {example['input']} [/INST] {example['output']} </s>"

def tokenize(example):
    prompt = format_prompt(example)
    tokenized = tokenizer(prompt, truncation=True, padding="max_length", max_length=512)
    tokenized["labels"] = tokenized["input_ids"].copy()
    return tokenized

tokenized_dataset = dataset.map(tokenize)

from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="rahul-llama-3b-lora",
    per_device_train_batch_size=2,
    num_train_epochs=12,
    logging_steps=1,
    save_strategy="epoch",
    fp16=True,
    report_to="none",
    learning_rate=2e-4,
    lr_scheduler_type="cosine",
    warmup_steps=10,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset
)

trainer.train()

# Save only the LoRA adapters (small size)
model.save_pretrained("rahul-llama3-gptme-lora")
tokenizer.save_pretrained("rahul-llama3-gptme-lora")

from peft import PeftModel, PeftConfig
from transformers import AutoModelForCausalLM, AutoTokenizer

# Load base + LoRA model
base_model = AutoModelForCausalLM.from_pretrained(
    model_id,
    load_in_4bit=True,
    device_map="auto",
    torch_dtype=torch.float16
)

tokenizer = AutoTokenizer.from_pretrained("rahul-llama3-gptme-lora")
model = PeftModel.from_pretrained(base_model, "rahul-llama3-gptme-lora")
model.eval()

def ask_GPTMe(query):
    prompt = f"<s>[INST] {query} [/INST]"
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=200, do_sample=True)

    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
    if "[/INST]" in decoded:
        answer = decoded.split("[/INST]")[-1].strip().replace("</s>", "").strip()
    else:
        answer = decoded.strip().replace("</s>", "").strip()

    return answer

inference_questions = [
    "What kind of applications has Rahul Hemal Shah built using ReactJS?",
    "Which machine learning libraries has Rahul Hemal Shah used in his projects?",
    "Can you summarize Rahul Hemal Shah's contribution to the SnapScore project in one sentence?",
    "Has Rahul Hemal Shah published any research in Springer? If yes, what was it about?",
    "Which internship gave Rahul Hemal Shah experience with SOAP APIs?",
    "What programming languages is Rahul Hemal Shah comfortable using across both frontend and backend development?",
    "How has Rahul Hemal Shah contributed to improving test coverage in his professional roles?",
    "Which tools has Rahul Hemal Shah used for version control and CI/CD?",
    "What does Rahul Hemal Shah's current academic coursework focus on at UMass Amherst?",
    "What deep learning models or architectures has Rahul Hemal Shah worked with?"
]

for question in inference_questions:
    print(f"Q: {question}")
    print(f"A: {ask_GPTMe(question)}")
    print("-" * 80)

# Example
# print(ask_GPTMe("What are Rahul Hemal Shah key strength areas?"))

!pip install -q evaluate nltk bert-score

!pip install rouge_score

import nltk
nltk.download('punkt')

inference_eval = [
    {
        "question": "What kind of applications has Rahul Hemal Shah built using ReactJS?",
        "reference": "Rahul Hemal Shah has built reusable components, and frontend portals using ReactJS, Angular React Router, Redux, and PowerApps."
    },
    {
        "question": "Which machine learning libraries has Rahul Hemal Shah used in his projects?",
        "reference": "Rahul Hemal Shah has worked with PyTorch, TensorFlow, Scikit-learn, Pandas, NumPy, and OpenCV in his academic and personal ML projects."
    },
    {
        "question": "Can you summarize Rahul Hemal Shah's contribution to the SnapScore project in one sentence?",
        "reference": "Rahul Hemal Shah developed SnapScore, a text-to-image evaluation tool using ResNet-LSTM architectures to assess image captioning accuracy."
    },
    {
        "question": "Has Rahul Hemal Shah published any research in Springer? If yes, what was it about?",
        "reference": "Yes, Rahul Hemal Shah has published two research papers in Springer on anomaly detection in drone-captured images using machine learning and deep learning techniques."
    },
    {
        "question": "Which internship gave Rahul Hemal Shah experience with SOAP APIs?",
        "reference": "Rahul Hemal Shah gained experience with SOAP APIs during his internship at Swym, where he built backend automation systems and recommendation engines."
    },
    {
        "question": "What programming languages is Rahul Hemal Shah comfortable using across both frontend and backend development?",
        "reference": "Rahul Hemal Shah is proficient in Python, JavaScript, TypeScript, C#, Java, SQL, and C++, which he has used across full-stack development roles."
    },
    {
        "question": "How has Rahul Hemal Shah contributed to improving test coverage in his professional roles?",
        "reference": "Rahul Hemal Shah improved unit test coverage to 65% at SLB, implemented CI/CD pipelines, and ensured bug-free delivery through rigorous testing practices."
    },
    {
        "question": "Which tools has Rahul Hemal Shah used for version control and CI/CD?",
        "reference": "Rahul Hemal Shah has used Git for version control and tools like Azure DevOps, Jenkins, and GitHub Actions for continuous integration and deployment."
    },
    {
        "question": "What does Rahul Hemal Shah's current academic coursework focus on at UMass Amherst?",
        "reference": "Rahul Hemal Shah's coursework at UMass Amherst includes Machine Learning, Advanced Algorithms, Natural Language Processing, Systems for Data Science, and Information Retrieval."
    },
    {
        "question": "What deep learning models or architectures has Rahul Hemal Shah worked with?",
        "reference": "Rahul Hemal Shah has worked with deep learning models like CNNs, RNNs (LSTM), and transformer-based architectures in both research and real-world applications."
    }
]

for item in inference_eval:
    item["prediction"] = ask_GPTMe(item["question"])
    print(item["prediction"])

import evaluate

# Load metrics
bleu = evaluate.load("bleu")
rouge = evaluate.load("rouge")
bertscore = evaluate.load("bertscore")

# Prepare lists
references = [x["reference"] for x in inference_eval]
predictions = [x["prediction"] for x in inference_eval]

# Compute scores
bleu_score = bleu.compute(predictions=predictions, references=[[r] for r in references])
rouge_score = rouge.compute(predictions=predictions, references=references)
bertscore_score = bertscore.compute(predictions=predictions, references=references, lang="en")

print("BLEU Score:", bleu_score["bleu"])
print("ROUGE-L:", rouge_score["rougeL"])
print("BERTScore (F1):", sum(bertscore_score["f1"]) / len(bertscore_score["f1"]))

!pip install -q sentence-transformers

from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer("all-MiniLM-L6-v2")

references = [x["reference"] for x in inference_eval]
predictions = [x["prediction"] for x in inference_eval]

# Encode all at once
emb_ref = model.encode(references, convert_to_tensor=True)
emb_pred = model.encode(predictions, convert_to_tensor=True)

# Compute pairwise cosine similarity (matrix)
cosine_sim_matrix = util.pytorch_cos_sim(emb_pred, emb_ref)

# Get diagonal (similarity between aligned pairs)
cosine_scores = cosine_sim_matrix.diag()

# Print scores
for i, score in enumerate(cosine_scores):
    print(f"Q{i+1}: Cosine Similarity = {score.item():.4f}")

# Average cosine similarity
avg_score = cosine_scores.mean().item()
print(f"\nAverage Cosine Similarity: {avg_score:.4f}")

ask_GPTMe("who is rahul hemal shah, give me a paragraph answer")

!pip install gradio

import gradio as gr

def chat_with_rahul(question):
    return ask_GPTMe(question)  # Your existing function

gr.Interface(fn=chat_with_rahul, inputs="text", outputs="text", title="GPT-Me: Ask anything about Rahul Hemal Shah").launch()

!pip install fastapi uvicorn transformers torch peft pyngrok

# Define your model and adapter path
adapter_path = "rahul-llama3-gptme-lora"

# Push model and adapter to Hugging Face
model.push_to_hub("rahulhshah/rahul-llama3-gptme-lora")
tokenizer.push_to_hub("rahulhshah/rahul-llama3-gptme-lora")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# from fastapi import FastAPI
# from pydantic import BaseModel
# 
# app = FastAPI(title="GPT-Me")
# 
# model_id = "meta-llama/Llama-3.2-3B-Instruct"
# adapter_path = "rahulhshah/rahul-llama3-gptme-lora"
# 
# tokenizer = AutoTokenizer.from_pretrained(adapter_path)
# base_model = AutoModelForCausalLM.from_pretrained(model_id, device_map="auto", torch_dtype=torch.float16)
# model = PeftModel.from_pretrained(base_model, adapter_path).to("cuda")
# model.eval()
# 
# class Query(BaseModel):
#     question: str
# 
# def ask_GPTMe(query):
#     prompt = f"<s>[INST] {query} [/INST]"
#     inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
#     with torch.no_grad():
#         outputs = model.generate(**inputs, max_new_tokens=200, do_sample=True, pad_token_id=tokenizer.eos_token_id)
# 
#     decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
#     if "[/INST]" in decoded:
#         answer = decoded.split("[/INST]")[-1].strip().replace("</s>", "").strip()
#     else:
#         answer = decoded.strip().replace("</s>", "").strip()
# 
#     return answer
# 
# @app.post("/ask")
# async def ask_question(query: Query):
#     response = ask_GPTMe(query.question)
#     return {"answer": response}
#

from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import torch

# Verify model path
adapter_path = "rahulhshah/rahul-llama3-gptme-lora"

tokenizer = AutoTokenizer.from_pretrained(adapter_path)
base_model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-3.2-3B-Instruct",
    device_map="auto",
    torch_dtype=torch.float16
)
model = PeftModel.from_pretrained(base_model, adapter_path).to("cuda")

print("✅ Model Loaded Successfully!")

from transformers import AutoTokenizer

# Verify model path
model_path = "rahulhshah/rahul-llama3-gptme-lora"

try:
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    print("Tokenizer loaded successfully!")
except Exception as e:
    print(f"Failed to load tokenizer: {e}")